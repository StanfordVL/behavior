<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Embodiments: actuation, sensing, grasping &mdash; BEHAVIOR 0.0.1 documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Setups" href="setups.html" />
    <link rel="prev" title="Training and Evaluating with BEHAVIOR" href="benchmarking.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> BEHAVIOR
          </a>
              <div class="version">
                0.0.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro.html">The BEHAVIOR Benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Training and Evaluating with BEHAVIOR</a></li>
</ul>
<p class="caption"><span class="caption-text">Components of BEHAVIOR</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Embodiments: actuation, sensing, grasping</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#behaviorrobot">BehaviorRobot</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#degrees-of-freedom">Degrees of Freedom</a></li>
<li class="toctree-l3"><a class="reference internal" href="#actuation-and-control">Actuation and Control</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#fetchrobot">FetchRobot</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Degrees of Freedom</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Actuation and Control</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#observations">Observations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#grasping-modes">Grasping Modes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#add-your-own-embodiment">Add your own embodiment!</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="setups.html">Setups</a></li>
<li class="toctree-l1"><a class="reference internal" href="activities.html">BDDL and the BEHAVIOR Dataset of Activity Definitions</a></li>
<li class="toctree-l1"><a class="reference internal" href="vr_demos.html">The BEHAVIOR Dataset of Human Demonstrations in Virtual Reality</a></li>
<li class="toctree-l1"><a class="reference internal" href="objects.html">The BEHAVIOR Dataset of Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a></li>
</ul>
<p class="caption"><span class="caption-text">Miscellaneous</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="issues.html">Trouble Shooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="projects.html">Projects using Gibson/iGibson</a></li>
<li class="toctree-l1"><a class="reference internal" href="acknowledgements.html">Acknowledgments</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">BEHAVIOR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Embodiments: actuation, sensing, grasping</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/agents.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="tex2jax_ignore mathjax_ignore section" id="embodiments-actuation-sensing-grasping">
<h1>Embodiments: actuation, sensing, grasping<a class="headerlink" href="#embodiments-actuation-sensing-grasping" title="Permalink to this headline"></a></h1>
<p>In principle, any robot embodiment can be used to participate in BEHAVIOR.
We provide two embodiments, the <code class="docutils literal notranslate"><span class="pre">BehaviorRobot</span></code> and the <code class="docutils literal notranslate"><span class="pre">FetchRobot</span></code>, fully implemented and functional.
Consider adding your own robot following the instructions <span class="xref myst">here</span>.</p>
<div class="section" id="behaviorrobot">
<h2>BehaviorRobot<a class="headerlink" href="#behaviorrobot" title="Permalink to this headline"></a></h2>
<p>The BehaviorRobot is composed of two hands, a torso, and a head where the cameras are mounted.
It has been used as avatar for humans to collect demos in virtual reality (more info <a class="reference internal" href="vr_demos.html"><span class="doc std std-doc">here</span></a>), but can also be controlled by an autonomous AI agent to participate in the BEHAVIOR.</p>
<div class="section" id="degrees-of-freedom">
<h3>Degrees of Freedom<a class="headerlink" href="#degrees-of-freedom" title="Permalink to this headline"></a></h3>
<p>The embodiment has 26 degrees of freedom decomposed as follows:</p>
<ul class="simple">
<li><p>Base: 6 DoF pose (position, orientation)</p></li>
<li><p>Head: 6 DoF pose (position, orientation) - relative to the current torso frame</p></li>
<li><p>Left and right hands: 6 DoF pose each - relative to the current torso frame</p></li>
<li><p>Left and right grippers: 1 DoF of close/open (aperture) of each gripper that correspond to the synchronized actuation of the 5 fingers</p></li>
</ul>
<p>Reference frames for the robot state in the BehaviorRobot:
<img alt="brobotframes.png" src="_images/brobotframes.png" /></p>
</div>
<div class="section" id="actuation-and-control">
<h3>Actuation and Control<a class="headerlink" href="#actuation-and-control" title="Permalink to this headline"></a></h3>
<p>Base, head, and hands are directly controlled in Cartesian space.
We provide a control interface for agents to control the motions of the BehaviorRobot by specifying:</p>
<ul class="simple">
<li><p>Base: Desired change in pose (delta pose, 6D) relative to the base frame in the previous time step.</p></li>
<li><p>Head: Desired change in pose (delta pose, 6D) relative to the base frame</p></li>
<li><p>Hands: Desired change in pose (delta pose, 2 x 6D) relative to the base frame</p></li>
<li><p>Grippers: Binary variable (2 x 1D) specifying if the grippers should close or open (change the gripper aperture DoF) at maximum speed</p></li>
</ul>
</div>
</div>
<div class="section" id="fetchrobot">
<h2>FetchRobot<a class="headerlink" href="#fetchrobot" title="Permalink to this headline"></a></h2>
<p>Fetch is composed of a mobile base, one arm and a movable head where the cameras are mounted.
It models the real robot Fetch.</p>
<div class="section" id="id1">
<h3>Degrees of Freedom<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p>The embodiment has 12 degrees of freedom decomposed as follows:</p>
<ul class="simple">
<li><p>Base: the base moves by actuating two active wheels. However, at effects of actuation and robot state, the rotation of the wheels is not relevant to the user; we consider instead the 3 DoF corresponding to the position on the floor plane and rotation around the floor plane normal</p></li>
<li><p>Trunk: 1 DoF of a prismatic joint that affect to both arm and head</p></li>
<li><p>Head: 2 DoF of pan (horizontal) &amp; tilt (vertical) directions</p></li>
<li><p>Arm: 6 DoF (revolute joints) for the arm that control the motion of the right hand</p></li>
<li><p>Gripper: 1 DoF of close/open (aperture) of the two-fingered gripper</p></li>
</ul>
<p>Reference frames for the robot state in the BehaviorRobot:
<img alt="fetchrobotframes.png" src="_images/fetchrobotframes.png" /></p>
</div>
<div class="section" id="id2">
<h3>Actuation and Control<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<p>TODO!!!!!
Base, head, and hands are directly controlled in Cartesian space.
We provide a control interface for agents to control the motions of the BehaviorRobot by specifying:</p>
<ul class="simple">
<li><p>Base: Desired change in pose (delta pose, 6D) relative to the base frame in the previous time step.</p></li>
<li><p>Head: Desired change in pose (delta pose, 6D) relative to the base frame</p></li>
<li><p>Hands: Desired change in pose (delta pose, 2 x 6D) relative to the base frame</p></li>
<li><p>Grippers: Binary variable (2 x 1D) specifying if the grippers should close or open (change of the gripper aperture DoF) at maximum speed</p></li>
</ul>
</div>
</div>
<div class="section" id="observations">
<h2>Observations<a class="headerlink" href="#observations" title="Permalink to this headline"></a></h2>
<p>Both agent embodiments have similar sensing capabilities based on virtual sensors on-board:</p>
<ul class="simple">
<li><p>Agent’s vision (default: 128x128 resolution, 120 degree FoV)</p>
<ul>
<li><p>RGB images</p></li>
<li><p>Depth images</p></li>
<li><p>Semantic and instance segmentation images</p></li>
<li><p>Activity relevant object mask (all objects included in the activity definition except the agent and the floor)</p></li>
</ul>
</li>
<li><p>Agent’s proprioception:</p>
<ul>
<li><p>Hand/end-effector pose in base frame (12-dim for BehaviorRobot, 6-dim for FetchRobot)</p></li>
<li><p>Head pose in base frame (6-dim for BehaviorRobot)</p></li>
<li><p>Hand aperture state (2-dim for BehaviorRobot, 1-dim for FetchRobot)</p></li>
<li><p>Hand tactile info (2-dim for BehaviorRobot, 1-dim for FetchRobot)</p></li>
<li><p>Joint states (9-dim for FetchRobot: trunk, head and arm joints)</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="grasping-modes">
<h2>Grasping Modes<a class="headerlink" href="#grasping-modes" title="Permalink to this headline"></a></h2>
<p>We acknowledge grasping as one of the most difficult elements in the physical interaction between the agents and the environment.
To alleviate the difficulty and enable research in other areas (e.g. planning, perception,…), we propose three grasping modes for BEHAVIOR:</p>
<ul class="simple">
<li><p><strong>Physical Grasping</strong>: This mode does not make any simplification in the grasping process.
Grasping is the result of a fully simulated interactions between the agent’s hand/fingers and the objects.
This mode is the most difficult but also the most realistic.</p></li>
<li><p><strong>Assistive Grasping</strong>: We simplify the grasping process with a mechanism that creates a rigid connection between the agent’s hand and an object if: 1) the gripper DoF is closed over a threshold, and 2) the object is “inside” the hand. The joint created by assistive grasping between hand and object is removed if the constraint is violated because of a large force or because the object and the hand move apart (the physics engine cannot enforce the rigid connection due to other constraints), or when the grasping DoF goes under the activation threshold.
The definition of “inside the hand” depends on the embodiment:</p>
<ul>
<li><p>For BehaviorRobot: an object object is “inside the hand” if it is intersected by rays projected from the palm to the fingertips of the hand, and the hand is applying a non-zero force to it.</p></li>
<li><p>For FetchRobot: and object “inside the hand” if it is in contact with both fingers of the end-effector, and the contact point is in the inner part of the fingers.
Assistive grasping simplifies the interaction but forces the agent to move in a realistic way to succeed in the grasp by placing the objects inside the hands, between the fingers.</p></li>
</ul>
</li>
<li><p><strong>Sticky Mitten</strong>: An alternative simplified grasping that creates a rigid connection between the hand and an object if the grasping DoF goes over a threshold while the hand is in contact with the object.
Using the sticky mitten, agents do not need to place the fingers around an object to grasp it.</p></li>
</ul>
</div>
<div class="section" id="add-your-own-embodiment">
<h2>Add your own embodiment!<a class="headerlink" href="#add-your-own-embodiment" title="Permalink to this headline"></a></h2>
<p>You can add your own embodiment to BEHAVIOR. For that, you will need to add it to iGibson following the specific instructions <span class="xref myst">here</span>TODO.</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="benchmarking.html" class="btn btn-neutral float-left" title="Training and Evaluating with BEHAVIOR" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="setups.html" class="btn btn-neutral float-right" title="Setups" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Stanford University 2018-2021.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>